{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aucrawler_NN_Experiment_with_Paris_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuvN9UMZaNtWUFP4QLRFJB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2leIgB2iWH4_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWreecDmAPWh"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRNvvthFFpzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26cbd778-6af0-4ed0-e1e8-b756e53e70b1"
      },
      "source": [
        "# ------------------------------------------------------------------------\n",
        "# (A) Dataset\n",
        "# ------------------------------------------------------------------------\n",
        "df = pd.read_excel(\"/content/20210421_PARIS_ENCODED.xlsx\", na_values=None)\n",
        "print(df.describe())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Unnamed: 0    ordinalDate  ...  literatureCharCount  provenanceCharCount\n",
            "count  8431.000000    8431.000000  ...          8431.000000          8431.000000\n",
            "mean   4215.000000  736197.226901  ...            25.167714            23.340173\n",
            "std    2433.964393    1380.600936  ...            90.462345            55.073347\n",
            "min       0.000000  732841.000000  ...             0.000000             0.000000\n",
            "25%    2107.500000  735675.000000  ...             0.000000             0.000000\n",
            "50%    4215.000000  736997.000000  ...             0.000000             0.000000\n",
            "75%    6322.500000  737039.000000  ...             0.000000            23.000000\n",
            "max    8430.000000  737403.000000  ...           899.000000           884.000000\n",
            "\n",
            "[8 rows x 24 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsF7CmSdDUdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0dbedd5-cbf3-4b81-c51c-1893af582355"
      },
      "source": [
        "# (2) drop rows with missing lotSold\n",
        "# - this would automatically remove all rows with 'postProcessedAuctionSaleTotalInUSD == 0' as well,\n",
        "#   because 'postProcessedAuctionSaleTotalInUSD' is the summation of lotSoldInUSD within an auction.\n",
        "df.drop(df.index[df['lotSoldInUsd'].isna()], inplace=True)\n",
        "print(df['lotSoldInUsd'].describe())\n",
        "\n",
        "df.drop(df.index[df['monthlyInflation'].isna()], inplace=True) # otherwise => Loss value = NaN when training\n",
        "df.drop(df.index[df['auctionLotAmount'].isna()], inplace=True) # otherwise => Loss value = NaN when training\n",
        "df.drop(df.index[df['postProcessedAuctionSaleTotalInUSD'].isna()], inplace=True) # otherwise => Loss value = NaN when training\n",
        "df.drop(df.index[df['lowerBoundInUsd'].isna()], inplace=True) # otherwise => Loss value = NaN when training\n",
        "df.drop(df.index[df['upperBoundInUsd'].isna()], inplace=True) # otherwise => Loss value = NaN when training\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    7.173000e+03\n",
            "mean     4.020723e+04\n",
            "std      2.723328e+05\n",
            "min      7.060410e+01\n",
            "25%      3.526562e+03\n",
            "50%      7.906937e+03\n",
            "75%      2.263600e+04\n",
            "max      1.905363e+07\n",
            "Name: lotSoldInUsd, dtype: float64\n",
            "      Unnamed: 0  ...                              saleroomNoticeContent\n",
            "137          137  ...                                                NaN\n",
            "138          138  ...                                                NaN\n",
            "139          139  ...                                                NaN\n",
            "140          140  ...                                                NaN\n",
            "141          141  ...                                                NaN\n",
            "...          ...  ...                                                ...\n",
            "8425        8425  ...                                                NaN\n",
            "8426        8426  ...                                                NaN\n",
            "8427        8427  ...  178\\nMerci de noter qu'il y a Ã  certains endro...\n",
            "8428        8428  ...                                                NaN\n",
            "8430        8430  ...  181\\nMerci de noter page 144 dans la Bibliogra...\n",
            "\n",
            "[7062 rows x 99 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlFUcGe9Slo-",
        "outputId": "fc62c232-92cf-4c81-cb66-60853087515e"
      },
      "source": [
        "# (3) splitting dataset into training data versus testing data\n",
        "# n_train = 400\n",
        "# df_num_row = df.shape[0]\n",
        "# odd_idx = [idx for idx in range(len(df_num_row)) if idx % 2 == 1]\n",
        "# even_idx = [idx for idx in range(len(df_num_row)) if idx % 2 == 0]\n",
        "\n",
        "X_cols = [\n",
        "    'ordinalDate', \n",
        "    'isJan', 'isFeb', 'isMar', 'isApr', 'isMay', 'isJun', 'isJul', 'isAug', 'isSep', 'isOct', 'isNov', 'isDec',\n",
        "    # 'is2000', 'is2001', 'is2002', 'is2003', 'is2004', 'is2005', 'is2006', 'is2007', 'is2008', 'is2009', 'is2010', 'is2011', 'is2012', 'is2013', 'is2014', 'is2015', 'is2016', 'is2017', 'is2018', 'is2019', 'is2020', 'is2021', \n",
        "    # 'isUS', 'isUK', 'isCN', 'isFR', 'isNL', 'isIT',\n",
        "    'monthlyInflation',\n",
        "    'auctionLotAmount', \n",
        "    # 'is8am', 'is9am', 'is10am', 'is11am', 'is12pm', 'is1pm', 'is2pm', 'is3pm', 'is4pm', 'is5pm', 'is6pm', 'is7pm',\n",
        "    'backupDescriptionCharCount',\n",
        "    'detailedDescriptionCharCount',\n",
        "    'IsFieldExist__CatalogueNote', 'CharCount__CatalogueNote', 'LangCount__CatalogueNote',\n",
        "    'postProcessedAuctionSaleTotalInUSD',\n",
        "    'lowerBoundInUsd', 'upperBoundInUsd',\n",
        "    'isExhibitedExist',\n",
        "    'literatureCharCount', \n",
        "    'isProvenanceExist','provenanceCharCount', \n",
        "    'isPropertyDetailsExist',\n",
        "    'isSubtitleExist', \n",
        "    'isSaleroomNoticeExist'\n",
        "]\n",
        "y_col = ['lotSoldInUsd']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[X_cols], df[y_col], test_size=0.2) \n",
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "# print(df.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      ordinalDate  isJan  ...  isSubtitleExist  isSaleroomNoticeExist\n",
            "6342       735640  False  ...             True                  False\n",
            "6639       735031  False  ...             True                  False\n",
            "8405       732841  False  ...             True                  False\n",
            "4811       736857  False  ...             True                  False\n",
            "6292       735759  False  ...             True                  False\n",
            "...           ...    ...  ...              ...                    ...\n",
            "2599       736997  False  ...            False                  False\n",
            "1644       737166  False  ...            False                  False\n",
            "3210       736997  False  ...            False                  False\n",
            "1581       737166  False  ...             True                  False\n",
            "2347       736997  False  ...            False                  False\n",
            "\n",
            "[5649 rows x 30 columns]\n",
            "      ordinalDate  isJan  ...  isSubtitleExist  isSaleroomNoticeExist\n",
            "3767       736997  False  ...            False                   True\n",
            "4932       736682  False  ...             True                  False\n",
            "5671       736682  False  ...            False                  False\n",
            "1030       737195  False  ...            False                   True\n",
            "7350       733759  False  ...            False                  False\n",
            "...           ...    ...  ...              ...                    ...\n",
            "1751       737166  False  ...            False                  False\n",
            "6955       734121  False  ...             True                  False\n",
            "5020       736682  False  ...             True                   True\n",
            "3559       736997  False  ...            False                  False\n",
            "7012       733932  False  ...             True                  False\n",
            "\n",
            "[1413 rows x 30 columns]\n",
            "      lotSoldInUsd\n",
            "6342     19813.500\n",
            "6639      6612.000\n",
            "8405     63916.800\n",
            "4811    161892.500\n",
            "6292     12711.375\n",
            "...            ...\n",
            "2599     11376.000\n",
            "1644      7053.125\n",
            "3210     17064.000\n",
            "1581      5642.500\n",
            "2347     49770.000\n",
            "\n",
            "[5649 rows x 1 columns]\n",
            "      lotSoldInUsd\n",
            "3767    65412.0000\n",
            "4932    16203.0000\n",
            "5671     7365.0000\n",
            "1030     4202.6250\n",
            "7350     6277.6875\n",
            "...            ...\n",
            "1751     1551.6875\n",
            "6955    58721.5950\n",
            "5020      958.0392\n",
            "3559    17064.0000\n",
            "7012   504563.4000\n",
            "\n",
            "[1413 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yNku7I0DpZB",
        "outputId": "9eb57c04-fc5a-46e7-c975-e8a4806b1b9b"
      },
      "source": [
        "# (4a - df directly) data scaling: scale numeric data\n",
        "# - shd be before one-hot encoding as that converts boolean columns into numeric columns.\n",
        "# scaler = MinMaxScaler()\n",
        "# numeric_cols = df.columns[df.dtypes.apply(lambda col: np.issubdtype(col, np.number))]\n",
        "# df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "# (4b - train & test) data scaling: scale numeric data\n",
        "# - shd be before one-hot encoding as that converts boolean columns into numeric columns.\n",
        "# scaler = MinMaxScaler()\n",
        "scaler = RobustScaler()\n",
        "numeric_cols = X_train.columns[X_train.dtypes.apply(lambda col: np.issubdtype(col, np.number))]\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "# X_test[numeric_cols] = scaler.fit_transform(X_test[numeric_cols])\n",
        "\n",
        "y_train = scaler.fit_transform(y_train)\n",
        "# y_test = scaler.fit_transform(y_test)\n",
        "\n",
        "print(X_train)\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      ordinalDate  isJan  ...  isSubtitleExist  isSaleroomNoticeExist\n",
            "6342    -1.492849  False  ...             True                  False\n",
            "6639    -2.162816  False  ...             True                  False\n",
            "8405    -4.572057  False  ...             True                  False\n",
            "4811    -0.154015  False  ...             True                  False\n",
            "6292    -1.361936  False  ...             True                  False\n",
            "...           ...    ...  ...              ...                    ...\n",
            "2599     0.000000  False  ...            False                  False\n",
            "1644     0.185919  False  ...            False                  False\n",
            "3210     0.000000  False  ...            False                  False\n",
            "1581     0.185919  False  ...             True                  False\n",
            "2347     0.000000  False  ...            False                  False\n",
            "\n",
            "[5649 rows x 30 columns]\n",
            "[[ 0.62133442]\n",
            " [-0.06263859]\n",
            " [ 2.90633743]\n",
            " ...\n",
            " [ 0.47888214]\n",
            " [-0.11286863]\n",
            " [ 2.17338818]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN0-BxYXFyvR",
        "outputId": "e0ee36c5-3458-4cf3-fb4b-f4a5e0e4cc90"
      },
      "source": [
        "# (5a - df directly) one-hot encoding: convert boolean into 0/1\n",
        "# for column in df.columns:\n",
        "#     if df[column].dtypes == 'bool':\n",
        "#         df[column] = df[column] * 1\n",
        "#         print(\"[*] Boolean column '{0}' has been converted into 0 & 1\".format(column))\n",
        "\n",
        "# (5b - train & test) one-hot encoding: convert boolean into 0/1\n",
        "for column in X_train.columns:\n",
        "    if X_train[column].dtypes == 'bool':\n",
        "        X_train[column] = X_train[column] * 1\n",
        "        X_test[column] = X_test[column] * 1\n",
        "        print(\"[*] Boolean column '{0}' has been converted into 0 & 1\".format(column))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*] Boolean column 'isJan' has been converted into 0 & 1\n",
            "[*] Boolean column 'isFeb' has been converted into 0 & 1\n",
            "[*] Boolean column 'isMar' has been converted into 0 & 1\n",
            "[*] Boolean column 'isApr' has been converted into 0 & 1\n",
            "[*] Boolean column 'isMay' has been converted into 0 & 1\n",
            "[*] Boolean column 'isJun' has been converted into 0 & 1\n",
            "[*] Boolean column 'isJul' has been converted into 0 & 1\n",
            "[*] Boolean column 'isAug' has been converted into 0 & 1\n",
            "[*] Boolean column 'isSep' has been converted into 0 & 1\n",
            "[*] Boolean column 'isOct' has been converted into 0 & 1\n",
            "[*] Boolean column 'isNov' has been converted into 0 & 1\n",
            "[*] Boolean column 'isDec' has been converted into 0 & 1\n",
            "[*] Boolean column 'IsFieldExist__CatalogueNote' has been converted into 0 & 1\n",
            "[*] Boolean column 'isExhibitedExist' has been converted into 0 & 1\n",
            "[*] Boolean column 'isProvenanceExist' has been converted into 0 & 1\n",
            "[*] Boolean column 'isPropertyDetailsExist' has been converted into 0 & 1\n",
            "[*] Boolean column 'isSubtitleExist' has been converted into 0 & 1\n",
            "[*] Boolean column 'isSaleroomNoticeExist' has been converted into 0 & 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XocdfJsHDka8",
        "outputId": "927ce6e4-ec0f-4725-8099-046982f0d9f9"
      },
      "source": [
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      ordinalDate  isJan  ...  isSubtitleExist  isSaleroomNoticeExist\n",
            "6342    -1.492849      0  ...                1                      0\n",
            "6639    -2.162816      0  ...                1                      0\n",
            "8405    -4.572057      0  ...                1                      0\n",
            "4811    -0.154015      0  ...                1                      0\n",
            "6292    -1.361936      0  ...                1                      0\n",
            "...           ...    ...  ...              ...                    ...\n",
            "2599     0.000000      0  ...                0                      0\n",
            "1644     0.185919      0  ...                0                      0\n",
            "3210     0.000000      0  ...                0                      0\n",
            "1581     0.185919      0  ...                1                      0\n",
            "2347     0.000000      0  ...                0                      0\n",
            "\n",
            "[5649 rows x 30 columns]\n",
            "      ordinalDate  isJan  ...  isSubtitleExist  isSaleroomNoticeExist\n",
            "3767       736997      0  ...                0                      1\n",
            "4932       736682      0  ...                1                      0\n",
            "5671       736682      0  ...                0                      0\n",
            "1030       737195      0  ...                0                      1\n",
            "7350       733759      0  ...                0                      0\n",
            "...           ...    ...  ...              ...                    ...\n",
            "1751       737166      0  ...                0                      0\n",
            "6955       734121      0  ...                1                      0\n",
            "5020       736682      0  ...                1                      1\n",
            "3559       736997      0  ...                0                      0\n",
            "7012       733932      0  ...                1                      0\n",
            "\n",
            "[1413 rows x 30 columns]\n",
            "[[ 0.62133442]\n",
            " [-0.06263859]\n",
            " [ 2.90633743]\n",
            " ...\n",
            " [ 0.47888214]\n",
            " [-0.11286863]\n",
            " [ 2.17338818]]\n",
            "      lotSoldInUsd\n",
            "3767    65412.0000\n",
            "4932    16203.0000\n",
            "5671     7365.0000\n",
            "1030     4202.6250\n",
            "7350     6277.6875\n",
            "...            ...\n",
            "1751     1551.6875\n",
            "6955    58721.5950\n",
            "5020      958.0392\n",
            "3559    17064.0000\n",
            "7012   504563.4000\n",
            "\n",
            "[1413 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fy5S-yefVo4Q",
        "outputId": "965c375d-fd3a-47f5-a7d3-c9bedc20b3f7"
      },
      "source": [
        "# EXP 001 - Mini-Batch Gradient Descent + 1 Hidden Layer\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD, Adam, Adamax, Nadam, Ftrl\n",
        "from keras.utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(len(X_cols), input_dim=len(X_cols), activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# pick one optimizer from below\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01)) # SGD\n",
        "\n",
        "plot_model(model, to_file='/content/model_1_1.png', show_shapes=True)\n",
        "\n",
        "X_train_v2 = np.asarray(X_train).astype(np.float32)\n",
        "y_train_v2 = np.asarray(y_train).astype(np.float32)\n",
        "X_test_v2 = np.asarray(X_test).astype(np.float32)\n",
        "y_test_v2 = np.asarray(y_test).astype(np.float32)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_v2, \n",
        "    y_train_v2, \n",
        "    validation_data=(X_test_v2, y_test_v2),\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    batch_size=20\n",
        ")\n",
        "\n",
        "mse_train = model.evaluate(X_train_v2, y_train_v2, verbose=1)\n",
        "mse_test = model.evaluate(X_test_v2, y_test_v2, verbose=1)\n",
        "\n",
        "model.predict(X_test_v2)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "pyplot.title('Mean Squared Error')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "283/283 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "283/283 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "177/177 [==============================] - 0s 988us/step - loss: nan\n",
            "45/45 [==============================] - 0s 939us/step - loss: nan\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_153 (Dense)            (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 961\n",
            "Trainable params: 961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXlklEQVR4nO3dfZRU9Z3n8fdHQBqEQNM8RGhJk+g4ou7BpMR44tnFoAK6CtGsMa4bMuMsmUkym0lWjzgan3cHnYy6niS6aNglmvgQs67M6IygkU121GhD2AlEtBvB0OAD4SmiomK++0dd9VJW0w9VXUXz+7zOuafv/f1+99b3131OfereW1WtiMDMzNJ1UL0LMDOz+nIQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFg1o9I+p+Srqt3HXZgcRBYn5O0QdLbkkaXtP9KUkhqqUNNfy1pvaRdkjok3VvrGqpN0pclvZvNKb+Mr3dttn9zEFitrAe++N6GpGOBofUoRNJc4D8Ap0TEMKAAPFaHOgb2wWGfjIhhJcvm7jx2T+vpo/qtDhwEVit3Al/Kbc8FfpgfIGmwpO9I+q2kVyTdJmlI1tco6R8kbZG0PVtvzu27XNK1kv5Z0muSlpaegeQcDzwSEesAIuLliFiYO9YkSf8nO84ySd+VdFfWN01SR0ndGySdkq1PlfSkpB2SXsr2PTg3NiR9TVIb0Ja1/VtJq7J9npD0r3Ljj5O0MqvlXqCh27/xElmdl0j6F+B1SYdn9Vwo6bfAzyQdJOlySS9KelXSDyWNyPZvKR3f21ps/+IgsFp5CviIpKMkDQDOA+4qGbMA+CNgCnA4MAG4Ius7CPgfwMeAicCbwHdL9j8f+BNgLHAwcNE+avmSpIslFbJ68n4MrABGA9dSDK3uehf4ZrbvicB04KslY+YAJwCTJR0HLAK+AjQB/x1YkoXiwcD/phiio4CfAOf0oJZyvgicAYwE9mRt/wY4CpgBfDlbTgY+Dgzjw7/n/Hg7EESEFy99ugAbgFOAy4G/AWYCy4CBQAAtgIDXgU/k9jsRWN/JMacA23Pby4HLc9tfBf5pHzX9e+DR7DG3Apdk7RMpPkEekhv7Y+CubH0a0FFufp08zl8BD+S2A/hsbvtW4NqSfZ6j+GT7r4HNgHJ9TwDXdfJYX85q35Fb1pXU+ae57Zasno/n2h4DvprbPhJ4J/tbfWi8lwNj8TU+q6U7gZ8Dkyi5LASMoXjPYIWk99oEDACQNBS4iWKINGb9wyUNiIh3s+2Xc8d7g+Kr2bIi4kfAjyQNovgK/UeSVgE7KQbM67nhLwKHdWeCkv4IuJHifYehFJ9AV5QM25hb/xgwV9Jf5toOBsZTfNLdFNkzcq6WfXkqIk7aR//GLtrGlzzGixTnMK6LY1g/5ktDVjMR8SLFm8anA/+rpPt3FC/3HB0RI7NlRBRv5gL8Z4qvTk+IiI9QfLUMxbCopKZ3IuInwL8AxwAvAY2SDskNm5hbf53cTe7sstKYXP+twFrgiKzOvy5TY/6JfSPwX3JzHhkRQyPi7qyWCcolY0ktvVHu64bzbZsphlP+8fYAr3RxDOvHHARWaxdSvDSSf8VNRPwBuB24SdJYAEkTJL13HXo4xaDYIWkUcGVvC8jeZnmGpOHZzdFZwNHAL7OwagWulnSwpJOAM3O7Pw80ZPsPoni5a3Cufzjwe2CXpD8G/qKLcm4H/lzSCSo65L3agCcpPgn/J0mDJJ0NTO3tvLvpbuCb2Q3zYcB/Be6NiD1d7Gf9mIPAaioi1kVEayfdlwDtwFOSfk/xGv6RWd/NwBCKZw5PAf9UQRm/p/hK/bcUr6PfAPxFRPzfrP98ijdzt1EMnPcvY0XETor3H+4ANlE8Q8i/i+iibP/XKD7J7/PzCdnv4j9SvCG7neL8v5z1vQ2cnW1vA77Ah8+kSp1Y5nMEx3exT94iPriEtx7YDfzlPvewfk97X340s1KSrgIOj4gL6l2LWV/wGYGZWeIcBGZmifOlITOzxPmMwMwscf3yA2WjR4+OlpaWepdhZtavrFix4ncRMaa0vV8GQUtLC62tnb0D0czMypFU9pPpvjRkZpY4B4GZWeIcBGZmieuX9wjMzHrqnXfeoaOjg927d9e7lD7X0NBAc3MzgwYN6tZ4B4GZJaGjo4Phw4fT0tLC3l/oemCJCLZu3UpHRweTJk3q1j6+NGRmSdi9ezdNTU0HdAgASKKpqalHZz4OAjNLxoEeAu/p6TwdBGZmiXMQmJnVwI4dO/j+97/f4/1OP/10duzY0QcVfcBBYGZWA50FwZ49+/7nbw8//DAjR47sq7IAv2vIzKwm5s+fz7p165gyZQqDBg2ioaGBxsZG1q5dy/PPP8+cOXPYuHEju3fv5hvf+Abz5s0DPvhKnV27djFr1ixOOukknnjiCSZMmMCDDz7IkCFDKq7NQWBmybn679fwm82/r+oxJ4//CFeeeXSn/QsWLGD16tWsWrWK5cuXc8YZZ7B69er33+K5aNEiRo0axZtvvsnxxx/POeecQ1NT017HaGtr4+677+b222/n3HPP5ac//SkXXFD5P85zEJiZ1cHUqVP3ep//LbfcwgMPPADAxo0baWtr+1AQTJo0iSlTpgDwqU99ig0bNlSlFgeBmSVnX6/ca+WQQw55f3358uU8+uijPPnkkwwdOpRp06aV/RzA4MGD318fMGAAb775ZlVq8c1iM7MaGD58OK+99lrZvp07d9LY2MjQoUNZu3YtTz31VE1r8xmBmVkNNDU18ZnPfIZjjjmGIUOGMG7cuPf7Zs6cyW233cZRRx3FkUceyac//ema1tYv/2dxoVAI/2MaM+uJZ599lqOOOqreZdRMuflKWhERhdKxvjRkZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmNdDbr6EGuPnmm3njjTeqXNEHHARmZjWwPwdBVT5ZLGkm8N+AAcAdEbGgpH8w8EPgU8BW4AsRsSHXPxH4DXBVRHynGjWZme1P8l9DfeqppzJ27Fjuu+8+3nrrLT73uc9x9dVX8/rrr3PuuefS0dHBu+++y7e//W1eeeUVNm/ezMknn8zo0aN5/PHHq15bxUEgaQDwPeBUoAN4RtKSiPhNbtiFwPaIOFzSecD1wBdy/TcC/1hpLWZm3fKP8+HlX1f3mB89FmYt6LQ7/zXUS5cu5f777+fpp58mIjjrrLP4+c9/zpYtWxg/fjwPPfQQUPwOohEjRnDjjTfy+OOPM3r06OrWnKnGpaGpQHtEvBARbwP3ALNLxswGFmfr9wPTlf13ZUlzgPXAmirUYma231u6dClLly7luOOO45Of/CRr166lra2NY489lmXLlnHJJZfwi1/8ghEjRtSknmpcGpoAbMxtdwAndDYmIvZI2gk0SdoNXELxbOKifT2IpHnAPICJEydWoWwzS9Y+XrnXQkRw6aWX8pWvfOVDfStXruThhx/m8ssvZ/r06VxxxRV9Xk+9bxZfBdwUEbu6GhgRCyOiEBGFMWPG9H1lZmZVlP8a6hkzZrBo0SJ27So+9W3atIlXX32VzZs3M3ToUC644AIuvvhiVq5c+aF9+0I1zgg2AYfltpuztnJjOiQNBEZQvGl8AvB5STcAI4E/SNodEd+tQl1mZvuN/NdQz5o1i/PPP58TTzwRgGHDhnHXXXfR3t7OxRdfzEEHHcSgQYO49dZbAZg3bx4zZ85k/PjxfXKzuOKvoc6e2J8HplN8wn8GOD8i1uTGfA04NiL+PLtZfHZEnFtynKuAXd1515C/htrMespfQ93511BXfEaQXfP/OvAIxbePLoqINZKuAVojYgnwA+BOSe3ANuC8Sh/XzMyqoyqfI4iIh4GHS9quyK3vBv5dF8e4qhq1mJlZz9T7ZrGZWc30x//I2Bs9naeDwMyS0NDQwNatWw/4MIgItm7dSkNDQ7f38T+vN7MkNDc309HRwZYtW+pdSp9raGigubm52+MdBGaWhEGDBjFp0qR6l7Ff8qUhM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBJXlSCQNFPSc5LaJc0v0z9Y0r1Z/y8ltWTtp0paIenX2c/PVqMeMzPrvoqDQNIA4HvALGAy8EVJk0uGXQhsj4jDgZuA67P23wFnRsSxwFzgzkrrMTOznqnGGcFUoD0iXoiIt4F7gNklY2YDi7P1+4HpkhQRv4qIzVn7GmCIpMFVqMnMzLqpGkEwAdiY2+7I2sqOiYg9wE6gqWTMOcDKiHirCjWZmVk3Dax3AQCSjqZ4uei0fYyZB8wDmDhxYo0qMzM78FXjjGATcFhuuzlrKztG0kBgBLA1224GHgC+FBHrOnuQiFgYEYWIKIwZM6YKZZuZGVQnCJ4BjpA0SdLBwHnAkpIxSyjeDAb4PPCziAhJI4GHgPkR8c9VqMXMzHqo4iDIrvl/HXgEeBa4LyLWSLpG0lnZsB8ATZLagW8B773F9OvA4cAVklZly9hKazIzs+5TRNS7hh4rFArR2tpa7zLMzPoVSSsiolDa7k8Wm5klzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeKqEgSSZkp6TlK7pPll+gdLujfr/6WkllzfpVn7c5JmVKMeMzPrvoqDQNIA4HvALGAy8EVJk0uGXQhsj4jDgZuA67N9JwPnAUcDM4HvZ8czM7MaqcYZwVSgPSJeiIi3gXuA2SVjZgOLs/X7gemSlLXfExFvRcR6oD07npmZ1Ug1gmACsDG33ZG1lR0TEXuAnUBTN/cFQNI8Sa2SWrds2VKFss3MDPrRzeKIWBgRhYgojBkzpt7lmJkdMKoRBJuAw3LbzVlb2TGSBgIjgK3d3NfMzPpQNYLgGeAISZMkHUzx5u+SkjFLgLnZ+ueBn0VEZO3nZe8qmgQcATxdhZrMzKybBlZ6gIjYI+nrwCPAAGBRRKyRdA3QGhFLgB8Ad0pqB7ZRDAuycfcBvwH2AF+LiHcrrcnMzLpPxRfm/UuhUIjW1tZ6l2Fm1q9IWhERhdL2fnOz2MzM+oaDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscRUFgaRRkpZJast+NnYybm42pk3S3KxtqKSHJK2VtEbSgkpqMTOz3qn0jGA+8FhEHAE8lm3vRdIo4ErgBGAqcGUuML4TEX8MHAd8RtKsCusxM7MeqjQIZgOLs/XFwJwyY2YAyyJiW0RsB5YBMyPijYh4HCAi3gZWAs0V1mNmZj1UaRCMi4iXsvWXgXFlxkwANua2O7K290kaCZxJ8azCzMxqaGBXAyQ9Cny0TNdl+Y2ICEnR0wIkDQTuBm6JiBf2MW4eMA9g4sSJPX0YMzPrRJdBEBGndNYn6RVJh0bES5IOBV4tM2wTMC233Qwsz20vBNoi4uYu6liYjaVQKPQ4cMzMrLxKLw0tAeZm63OBB8uMeQQ4TVJjdpP4tKwNSdcBI4C/qrAOMzPrpUqDYAFwqqQ24JRsG0kFSXcARMQ24FrgmWy5JiK2SWqmeHlpMrBS0ipJf1ZhPWZm1kOK6H9XWQqFQrS2tta7DDOzfkXSiogolLb7k8VmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWuIqCQNIoScsktWU/GzsZNzcb0yZpbpn+JZJWV1KLmZn1TqVnBPOBxyLiCOCxbHsvkkYBVwInAFOBK/OBIelsYFeFdZiZWS9VGgSzgcXZ+mJgTpkxM4BlEbEtIrYDy4CZAJKGAd8CrquwDjMz66VKg2BcRLyUrb8MjCszZgKwMbfdkbUBXAv8HfBGVw8kaZ6kVkmtW7ZsqaBkMzPLG9jVAEmPAh8t03VZfiMiQlJ094ElTQE+ERHflNTS1fiIWAgsBCgUCt1+HDMz27cugyAiTumsT9Irkg6NiJckHQq8WmbYJmBabrsZWA6cCBQkbcjqGCtpeURMw8zMaqbSS0NLgPfeBTQXeLDMmEeA0yQ1ZjeJTwMeiYhbI2J8RLQAJwHPOwTMzGqv0iBYAJwqqQ04JdtGUkHSHQARsY3ivYBnsuWarM3MzPYDiuh/l9sLhUK0trbWuwwzs35F0oqIKJS2+5PFZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmljgHgZlZ4hQR9a6hxyRtAV6sdx09NBr4Xb2LqDHPOQ2ec//xsYgYU9rYL4OgP5LUGhGFetdRS55zGjzn/s+XhszMEucgMDNLnIOgdhbWu4A68JzT4Dn3c75HYGaWOJ8RmJklzkFgZpY4B0EVSRolaZmktuxnYyfj5mZj2iTNLdO/RNLqvq+4cpXMWdJQSQ9JWitpjaQFta2+ZyTNlPScpHZJ88v0D5Z0b9b/S0ktub5Ls/bnJM2oZd2V6O2cJZ0qaYWkX2c/P1vr2nujkr9x1j9R0i5JF9Wq5qqICC9VWoAbgPnZ+nzg+jJjRgEvZD8bs/XGXP/ZwI+B1fWeT1/PGRgKnJyNORj4BTCr3nPqZJ4DgHXAx7Na/x8wuWTMV4HbsvXzgHuz9cnZ+MHApOw4A+o9pz6e83HA+Gz9GGBTvefTl/PN9d8P/AS4qN7z6cniM4Lqmg0sztYXA3PKjJkBLIuIbRGxHVgGzASQNAz4FnBdDWqtll7POSLeiIjHASLibWAl0FyDmntjKtAeES9ktd5Dce55+d/F/cB0Scra74mItyJiPdCeHW9/1+s5R8SvImJz1r4GGCJpcE2q7r1K/sZImgOspzjffsVBUF3jIuKlbP1lYFyZMROAjbntjqwN4Frg74A3+qzC6qt0zgBIGgmcCTzWF0VWQZdzyI+JiD3ATqCpm/vujyqZc945wMqIeKuP6qyWXs83exF3CXB1DeqsuoH1LqC/kfQo8NEyXZflNyIiJHX7vbmSpgCfiIhvll53rLe+mnPu+AOBu4FbIuKF3lVp+yNJRwPXA6fVu5Y+dhVwU0Tsyk4Q+hUHQQ9FxCmd9Ul6RdKhEfGSpEOBV8sM2wRMy203A8uBE4GCpA0U/y5jJS2PiGnUWR/O+T0LgbaIuLkK5faVTcBhue3mrK3cmI4s3EYAW7u57/6okjkjqRl4APhSRKzr+3IrVsl8TwA+L+kGYCTwB0m7I+K7fV92FdT7JsWBtAB/y943Tm8oM2YUxeuIjdmyHhhVMqaF/nOzuKI5U7wf8lPgoHrPpYt5DqR4k3sSH9xIPLpkzNfY+0bifdn60ex9s/gF+sfN4krmPDIbf3a951GL+ZaMuYp+drO47gUcSAvFa6OPAW3Ao7knuwJwR27cn1K8YdgO/EmZ4/SnIOj1nCm+4grgWWBVtvxZvee0j7meDjxP8Z0ll2Vt1wBnZesNFN8x0g48DXw8t+9l2X7PsZ++M6qacwYuB17P/V1XAWPrPZ++/BvnjtHvgsBfMWFmlji/a8jMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS9/8Bs+G2sgi/FB8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c42GnqtIIE3a",
        "outputId": "7b5307da-693f-4f36-fd24-f366f8e7837a"
      },
      "source": [
        "# EXP 002 - Mini-Batch Gradient Descent + 10 Hidden Layers\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD, Adam, Adamax, Nadam, Ftrl\n",
        "from keras.utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_dim=len(X_cols), activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(512, input_dim=1024, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(256, input_dim=512, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(128, input_dim=256, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(64, input_dim=128, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(32, input_dim=64, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(16, input_dim=32, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(8, input_dim=16, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(4, input_dim=8, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(2, input_dim=4, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# pick one optimizer from below\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01)) # SGD\n",
        "\n",
        "plot_model(model, to_file='/content/model_1.png', show_shapes=True)\n",
        "\n",
        "X_train_v2 = np.asarray(X_train).astype(np.float32)\n",
        "y_train_v2 = np.asarray(y_train).astype(np.float32)\n",
        "X_test_v2 = np.asarray(X_test).astype(np.float32)\n",
        "y_test_v2 = np.asarray(y_test).astype(np.float32)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_v2, \n",
        "    y_train_v2, \n",
        "    validation_data=(X_test_v2, y_test_v2),\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    batch_size=20\n",
        ")\n",
        "\n",
        "mse_train = model.evaluate(X_train_v2, y_train_v2, verbose=1)\n",
        "mse_test = model.evaluate(X_test_v2, y_test_v2, verbose=1)\n",
        "\n",
        "model.predict(X_test_v2)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "pyplot.title('Mean Squared Error')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "283/283 [==============================] - 3s 9ms/step - loss: 264.3548 - val_loss: 18273019904.0000\n",
            "Epoch 2/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 388.4214 - val_loss: 18273007616.0000\n",
            "Epoch 3/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 552.3590 - val_loss: 18273028096.0000\n",
            "Epoch 4/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 107.7987 - val_loss: 18273009664.0000\n",
            "Epoch 5/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 151.6110 - val_loss: 18272991232.0000\n",
            "Epoch 6/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 238.6589 - val_loss: 18273011712.0000\n",
            "Epoch 7/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 610.8362 - val_loss: 18273011712.0000\n",
            "Epoch 8/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 125.2169 - val_loss: 18272989184.0000\n",
            "Epoch 9/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 139.5231 - val_loss: 18273005568.0000\n",
            "Epoch 10/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 544.6281 - val_loss: 18273028096.0000\n",
            "Epoch 11/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 450.2863 - val_loss: 18272995328.0000\n",
            "Epoch 12/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 80.1300 - val_loss: 18272985088.0000\n",
            "Epoch 13/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 606.4649 - val_loss: 18273028096.0000\n",
            "Epoch 14/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 507.6932 - val_loss: 18272995328.0000\n",
            "Epoch 15/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 558.5159 - val_loss: 18273024000.0000\n",
            "Epoch 16/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 200.6912 - val_loss: 18273021952.0000\n",
            "Epoch 17/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 374.1196 - val_loss: 18273024000.0000\n",
            "Epoch 18/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 93.3474 - val_loss: 18272976896.0000\n",
            "Epoch 19/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 225.6328 - val_loss: 18273024000.0000\n",
            "Epoch 20/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 72.0578 - val_loss: 18272962560.0000\n",
            "Epoch 21/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 290.3019 - val_loss: 18273005568.0000\n",
            "Epoch 22/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 293.1880 - val_loss: 18273028096.0000\n",
            "Epoch 23/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 308.8895 - val_loss: 18273019904.0000\n",
            "Epoch 24/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 214.9087 - val_loss: 18273019904.0000\n",
            "Epoch 25/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 397.5605 - val_loss: 18273032192.0000\n",
            "Epoch 26/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 118.8375 - val_loss: 18273007616.0000\n",
            "Epoch 27/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 143.8104 - val_loss: 18273011712.0000\n",
            "Epoch 28/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 223.0058 - val_loss: 18273015808.0000\n",
            "Epoch 29/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 73.7226 - val_loss: 18272968704.0000\n",
            "Epoch 30/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 138.1237 - val_loss: 18272995328.0000\n",
            "Epoch 31/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 73.8542 - val_loss: 18272958464.0000\n",
            "Epoch 32/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 455.9125 - val_loss: 18273009664.0000\n",
            "Epoch 33/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 230.2257 - val_loss: 18273011712.0000\n",
            "Epoch 34/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 193.7137 - val_loss: 18273015808.0000\n",
            "Epoch 35/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 65.4251 - val_loss: 18272966656.0000\n",
            "Epoch 36/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 95.1000 - val_loss: 18272989184.0000\n",
            "Epoch 37/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 143.8078 - val_loss: 18273007616.0000\n",
            "Epoch 38/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 142.1056 - val_loss: 18272995328.0000\n",
            "Epoch 39/50\n",
            "283/283 [==============================] - 2s 8ms/step - loss: 122.7403 - val_loss: 18273005568.0000\n",
            "Epoch 40/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 242.0842 - val_loss: 18273007616.0000\n",
            "Epoch 41/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 442.7861 - val_loss: 18273024000.0000\n",
            "Epoch 42/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 127.3709 - val_loss: 18273005568.0000\n",
            "Epoch 43/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 98.8673 - val_loss: 18272991232.0000\n",
            "Epoch 44/50\n",
            "283/283 [==============================] - 3s 9ms/step - loss: 527.0716 - val_loss: 18273011712.0000\n",
            "Epoch 45/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 143.0578 - val_loss: 18273011712.0000\n",
            "Epoch 46/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 312.3046 - val_loss: 18273021952.0000\n",
            "Epoch 47/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 112.4454 - val_loss: 18273005568.0000\n",
            "Epoch 48/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 652.2135 - val_loss: 18273021952.0000\n",
            "Epoch 49/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 601.8993 - val_loss: 18273028096.0000\n",
            "Epoch 50/50\n",
            "283/283 [==============================] - 2s 9ms/step - loss: 84.4880 - val_loss: 18272968704.0000\n",
            "177/177 [==============================] - 1s 3ms/step - loss: 234.9090\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 18272968704.0000\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_155 (Dense)            (None, 1024)              31744     \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_159 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_161 (Dense)            (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_163 (Dense)            (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_164 (Dense)            (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 731,817\n",
            "Trainable params: 731,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C5UH3Mt0Hr30",
        "outputId": "efc1d52f-2e36-4f6c-f80e-d4010015cb1c"
      },
      "source": [
        "# EXP 003 - Adam + 1 Hidden Layer\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD, Adam, Adamax, Nadam, Ftrl\n",
        "from keras.utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(len(X_cols), input_dim=len(X_cols), activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# pick one optimizer from below\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.01)) # Adam\n",
        "\n",
        "plot_model(model, to_file='/content/model_2.png', show_shapes=True)\n",
        "\n",
        "X_train_v2 = np.asarray(X_train).astype(np.float32)\n",
        "y_train_v2 = np.asarray(y_train).astype(np.float32)\n",
        "X_test_v2 = np.asarray(X_test).astype(np.float32)\n",
        "y_test_v2 = np.asarray(y_test).astype(np.float32)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_v2, \n",
        "    y_train_v2, \n",
        "    validation_data=(X_test_v2, y_test_v2),\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "mse_train = model.evaluate(X_train_v2, y_train_v2, verbose=1)\n",
        "mse_test = model.evaluate(X_test_v2, y_test_v2, verbose=1)\n",
        "\n",
        "model.predict(X_test_v2)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "pyplot.title('Mean Squared Error')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "177/177 [==============================] - 1s 2ms/step - loss: 3000.8450 - val_loss: 161985916305408.0000\n",
            "Epoch 2/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 285.2825 - val_loss: 501638255083520.0000\n",
            "Epoch 3/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 482.3273 - val_loss: 733791605751808.0000\n",
            "Epoch 4/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 486.5195 - val_loss: 1134136177721344.0000\n",
            "Epoch 5/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 811.5461 - val_loss: 1612564395982848.0000\n",
            "Epoch 6/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 176.6481 - val_loss: 1866480312385536.0000\n",
            "Epoch 7/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 282.2430 - val_loss: 2373395706544128.0000\n",
            "Epoch 8/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 647.8962 - val_loss: 2553861105516544.0000\n",
            "Epoch 9/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 192.4011 - val_loss: 3453862912458752.0000\n",
            "Epoch 10/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 162.1527 - val_loss: 4402006470950912.0000\n",
            "Epoch 11/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 42.2910 - val_loss: 4938995494551552.0000\n",
            "Epoch 12/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 521.5866 - val_loss: 6333694319001600.0000\n",
            "Epoch 13/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 78.6891 - val_loss: 6259842893217792.0000\n",
            "Epoch 14/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 149.8092 - val_loss: 7700825358991360.0000\n",
            "Epoch 15/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 273.6190 - val_loss: 7806445584121856.0000\n",
            "Epoch 16/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 127.8776 - val_loss: 9238995418480640.0000\n",
            "Epoch 17/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 157.4890 - val_loss: 12930221309165568.0000\n",
            "Epoch 18/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 80.8045 - val_loss: 12891473187962880.0000\n",
            "Epoch 19/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 287.5842 - val_loss: 11026160301375488.0000\n",
            "Epoch 20/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 155.7510 - val_loss: 13374396089499648.0000\n",
            "Epoch 21/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 146.8274 - val_loss: 13625216810876928.0000\n",
            "Epoch 22/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 183.1686 - val_loss: 14063308843778048.0000\n",
            "Epoch 23/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 231.5214 - val_loss: 16118065221599232.0000\n",
            "Epoch 24/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 460.6648 - val_loss: 16076704686538752.0000\n",
            "Epoch 25/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 230.4445 - val_loss: 15296471263870976.0000\n",
            "Epoch 26/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 155.5661 - val_loss: 18574629748604928.0000\n",
            "Epoch 27/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 398.9422 - val_loss: 19785239295426560.0000\n",
            "Epoch 28/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 746.5270 - val_loss: 20296484285054976.0000\n",
            "Epoch 29/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 259.5956 - val_loss: 28977461446311936.0000\n",
            "Epoch 30/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 229.3558 - val_loss: 29861314176221184.0000\n",
            "Epoch 31/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 51.6950 - val_loss: 28763853395329024.0000\n",
            "Epoch 32/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 113.5211 - val_loss: 33428948087996416.0000\n",
            "Epoch 33/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 305.4424 - val_loss: 33879724233064448.0000\n",
            "Epoch 34/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 156.9621 - val_loss: 37684300753141760.0000\n",
            "Epoch 35/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 102.6852 - val_loss: 40035786757767168.0000\n",
            "Epoch 36/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 336.7403 - val_loss: 42119176608808960.0000\n",
            "Epoch 37/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 153.2258 - val_loss: 39056156257157120.0000\n",
            "Epoch 38/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 43.7005 - val_loss: 39303065337069568.0000\n",
            "Epoch 39/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 237.1982 - val_loss: 34517690085277696.0000\n",
            "Epoch 40/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 282.2944 - val_loss: 40592337209917440.0000\n",
            "Epoch 41/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 34.7752 - val_loss: 45682818348482560.0000\n",
            "Epoch 42/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 232.0750 - val_loss: 49561444399710208.0000\n",
            "Epoch 43/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 83.2420 - val_loss: 39773510284869632.0000\n",
            "Epoch 44/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 205.3199 - val_loss: 43810483190366208.0000\n",
            "Epoch 45/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 154.6345 - val_loss: 47007880183808000.0000\n",
            "Epoch 46/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 231.6433 - val_loss: 58582439089405952.0000\n",
            "Epoch 47/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 154.4879 - val_loss: 49787419809021952.0000\n",
            "Epoch 48/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 174.8795 - val_loss: 48634697831415808.0000\n",
            "Epoch 49/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 305.7961 - val_loss: 51960037605638144.0000\n",
            "Epoch 50/50\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 98.9716 - val_loss: 54829049989562368.0000\n",
            "177/177 [==============================] - 0s 948us/step - loss: 141.2355\n",
            "45/45 [==============================] - 0s 928us/step - loss: 54829049989562368.0000\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_166 (Dense)            (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 961\n",
            "Trainable params: 961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b8oUuhB5kE19",
        "outputId": "789b9b6e-a703-46e6-a206-2c9ee7693677"
      },
      "source": [
        "# EXP 004 - Adam + 10 Hidden Layer\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD, Adam, Adamax, Nadam, Ftrl\n",
        "from keras.utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_dim=len(X_cols), activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(512, input_dim=1024, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(256, input_dim=512, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(128, input_dim=256, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(64, input_dim=128, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(32, input_dim=64, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(16, input_dim=32, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(8, input_dim=16, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(4, input_dim=8, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(2, input_dim=4, activation='relu', kernel_initializer='he_uniform')) # number of nodes = number of features\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# pick one optimizer from below\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.01)) # Adam\n",
        "\n",
        "plot_model(model, to_file='/content/model_2.png', show_shapes=True)\n",
        "\n",
        "X_train_v2 = np.asarray(X_train).astype(np.float32)\n",
        "y_train_v2 = np.asarray(y_train).astype(np.float32)\n",
        "X_test_v2 = np.asarray(X_test).astype(np.float32)\n",
        "y_test_v2 = np.asarray(y_test).astype(np.float32)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_v2, \n",
        "    y_train_v2, \n",
        "    validation_data=(X_test_v2, y_test_v2),\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "mse_train = model.evaluate(X_train_v2, y_train_v2, verbose=1)\n",
        "mse_test = model.evaluate(X_test_v2, y_test_v2, verbose=1)\n",
        "\n",
        "model.predict(X_test_v2)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "pyplot.title('Mean Squared Error')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1912.4617 - val_loss: 18273079296.0000\n",
            "Epoch 2/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 144.6133 - val_loss: 18273034240.0000\n",
            "Epoch 3/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 233.7934 - val_loss: 18273017856.0000\n",
            "Epoch 4/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 378.3855 - val_loss: 18273011712.0000\n",
            "Epoch 5/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 326.3635 - val_loss: 18273011712.0000\n",
            "Epoch 6/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 505.7330 - val_loss: 18273011712.0000\n",
            "Epoch 7/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 158.4224 - val_loss: 18273001472.0000\n",
            "Epoch 8/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 55.7872 - val_loss: 18273011712.0000\n",
            "Epoch 9/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 195.0423 - val_loss: 18272995328.0000\n",
            "Epoch 10/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 125.2987 - val_loss: 18272999424.0000\n",
            "Epoch 11/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 120.5277 - val_loss: 18272997376.0000\n",
            "Epoch 12/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 273.8921 - val_loss: 18273005568.0000\n",
            "Epoch 13/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 112.1562 - val_loss: 18273005568.0000\n",
            "Epoch 14/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 155.3220 - val_loss: 18272999424.0000\n",
            "Epoch 15/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 255.8261 - val_loss: 18273011712.0000\n",
            "Epoch 16/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 107.8888 - val_loss: 18272995328.0000\n",
            "Epoch 17/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 198.9797 - val_loss: 18272999424.0000\n",
            "Epoch 18/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 89.3042 - val_loss: 18272995328.0000\n",
            "Epoch 19/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 267.1518 - val_loss: 18273005568.0000\n",
            "Epoch 20/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 69.1008 - val_loss: 18272995328.0000\n",
            "Epoch 21/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 516.8240 - val_loss: 18273005568.0000\n",
            "Epoch 22/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 98.3033 - val_loss: 18272993280.0000\n",
            "Epoch 23/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 237.8191 - val_loss: 18273011712.0000\n",
            "Epoch 24/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 97.4135 - val_loss: 18272999424.0000\n",
            "Epoch 25/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 233.4927 - val_loss: 18273005568.0000\n",
            "Epoch 26/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 405.1965 - val_loss: 18273015808.0000\n",
            "Epoch 27/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 291.6978 - val_loss: 18273005568.0000\n",
            "Epoch 28/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 134.3284 - val_loss: 18272995328.0000\n",
            "Epoch 29/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 316.0584 - val_loss: 18273011712.0000\n",
            "Epoch 30/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 261.7119 - val_loss: 18273005568.0000\n",
            "Epoch 31/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 392.6169 - val_loss: 18273015808.0000\n",
            "Epoch 32/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 122.5999 - val_loss: 18272995328.0000\n",
            "Epoch 33/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 468.6514 - val_loss: 18273011712.0000\n",
            "Epoch 34/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 136.7851 - val_loss: 18273005568.0000\n",
            "Epoch 35/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 93.5169 - val_loss: 18272995328.0000\n",
            "Epoch 36/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 248.9950 - val_loss: 18273001472.0000\n",
            "Epoch 37/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 99.5067 - val_loss: 18272995328.0000\n",
            "Epoch 38/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 177.9213 - val_loss: 18272999424.0000\n",
            "Epoch 39/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 102.1673 - val_loss: 18272989184.0000\n",
            "Epoch 40/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 306.2179 - val_loss: 18273011712.0000\n",
            "Epoch 41/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 227.6924 - val_loss: 18273011712.0000\n",
            "Epoch 42/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 874.7806 - val_loss: 18273015808.0000\n",
            "Epoch 43/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 96.3308 - val_loss: 18272995328.0000\n",
            "Epoch 44/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 416.2507 - val_loss: 18273011712.0000\n",
            "Epoch 45/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 204.1921 - val_loss: 18273011712.0000\n",
            "Epoch 46/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 159.8041 - val_loss: 18273005568.0000\n",
            "Epoch 47/50\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 287.6749 - val_loss: 18273005568.0000\n",
            "Epoch 48/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 176.6253 - val_loss: 18273001472.0000\n",
            "Epoch 49/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 277.4255 - val_loss: 18273005568.0000\n",
            "Epoch 50/50\n",
            "177/177 [==============================] - 2s 14ms/step - loss: 146.8932 - val_loss: 18272999424.0000\n",
            "177/177 [==============================] - 1s 3ms/step - loss: 234.6866\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 18272999424.0000\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_168 (Dense)            (None, 1024)              31744     \n",
            "_________________________________________________________________\n",
            "dense_169 (Dense)            (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_170 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_171 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_172 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_173 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_174 (Dense)            (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_175 (Dense)            (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_176 (Dense)            (None, 4)                 36        \n",
            "_________________________________________________________________\n",
            "dense_177 (Dense)            (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_178 (Dense)            (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 731,817\n",
            "Trainable params: 731,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}